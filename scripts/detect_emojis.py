import cv2
import torch
from torchvision import transforms, models
from PIL import Image
import os
import sys

# YOLOv5 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
yolo_model = torch.hub.load('ultralytics/yolov5', 'custom', path="D:\\git\\img_mk\\models\\yolov5\\best.pt")

# ê°ì • ë¶„ë¥˜ ëª¨ë¸ ì •ì˜ ë° ìƒí˜¸ ì‚¬ì „ ë¡œë“œ
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# InceptionV3 ê¸°ë°˜ì˜ ëª¨ë¸ ì •ì˜
emotion_model = models.inception_v3(pretrained=False)
emotion_model.fc = torch.nn.Sequential(
    torch.nn.Linear(emotion_model.fc.in_features, 256),
    torch.nn.ReLU(),
    torch.nn.Dropout(0.5),
    torch.nn.Linear(256, 7),  # ê°ì • í´ë˜ìŠ¤ ê°œìˆ˜ (ì˜ˆì‹œë¡œ 7ê°œ í´ë˜ìŠ¤ ì‚¬ìš©)
    torch.nn.LogSoftmax(dim=1)
)
emotion_model.load_state_dict(torch.load("D:\\git\\img_mk\\models\\emotion_model.pth"))
emotion_model = emotion_model.to(device)
emotion_model.eval()

# ì´ëª¨ì§€ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
emotion_to_emoji = {
    '0': 'ğŸ˜ ',
    'anxiety': 'ğŸ˜°',
    'happy': 'ğŸ˜Š',
    'neutrality': 'ğŸ˜',
    'panic': 'ğŸ˜±',
    'sad': 'ğŸ˜¢',
    'wound': 'ğŸ§•'
}

# ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
image_folder = 'D:/kor_face_ai/real_t'

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((299, 299)),  # InceptionV3 ì…ë ¥ í¬ê¸°ì— ë§ì¶° ì¡°ì •
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# ì´ë¯¸ì§€ ì¶œë ¥ í´ë” ê²½ë¡œ ì„¤ì •
output_folder = "D:\\git\\img_mk\\results\\output_images"
if not os.path.exists(output_folder):
    os.makedirs(output_folder)

# ì´ë¯¸ì§€ í´ë” ë‚´ ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬
image_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]
total_images = len(image_files)

# ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜
def process_image(image_path, output_path):
    # ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
    img = cv2.imread(image_path)
    if img is None:
        print(f"Error loading image: {image_path}")
        return
    
    results = yolo_model(img)
    if len(results.xyxy[0]) == 0:
        print(f"No objects detected in image: {image_path}")
        return

    # ë°”ìš´ë”© ë°•ìŠ¤ ì–»ê¸°
    for det in results.xyxy[0]:
        x1, y1, x2, y2, conf, cls = map(int, det)
        face_img = img[y1:y2, x1:x2]

        # ì–¼êµ´ ì´ë¯¸ì§€ PIL í˜•ì‹ìœ¼ë¡œ ë³€í™˜ í›„ ê°ì • ì˜ˆì¸¡
        face_pil = Image.fromarray(cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB))
        face_tensor = transform(face_pil).unsqueeze(0).to(device)
        emotion_output = emotion_model(face_tensor)
        _, predicted = torch.max(emotion_output, 1)
        emotion_label = predicted.item()

        # ê°ì • ë ˆì´ë¸”ì— ë”°ë¼ ì´ëª¨ì§€ ì„ íƒ
        emotion = list(emotion_to_emoji.keys())[emotion_label]
        emoji = emotion_to_emoji[emotion]
        
        # ë””ë²„ê¹…ìš© ì½˜ì†” ì¶œë ¥
        print(f"Predicted emotion: {emotion}, Emoji: {emoji}")

        # ì´ë¯¸ì§€ì— ì´ëª¨ì§€ ë§¤í•‘
        try:
            cv2.putText(img, emoji, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        except Exception as e:
            # í°íŠ¸ ë¬¸ì œë¡œ ì´ëª¨ì§€ ì¶œë ¥ì´ ì•ˆ ë˜ëŠ” ê²½ìš° ê°ì • í…ìŠ¤íŠ¸ ì¶œë ¥
            print(f"Failed to render emoji due to: {e}")
            cv2.putText(img, emotion, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)

    # ê²°ê³¼ ì €ì¥ (JPG í˜•ì‹ìœ¼ë¡œ ì €ì¥)
    if not cv2.imwrite(output_path.replace('.png', '.jpg'), img):
        print(f"Error saving image: {output_path}")

# ì´ë¯¸ì§€ í¬ë§· ì „ì²´ ì²˜ë¦¬
for idx, image_file in enumerate(image_files, start=1):
    image_path = os.path.join(image_folder, image_file)
    output_path = os.path.join(output_folder, os.path.basename(image_path).replace('.png', '.jpg'))
    
    # ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘
    process_image(image_path, output_path)
    
    # ì§„í–‰ìƒíƒœ ì•Œë¦¼ ì¶œë ¥
    progress = (idx / total_images) * 100
    sys.stdout.write(f"\rProgress: {idx}/{total_images} ({progress:.2f}%)")
    sys.stdout.flush()

print("\nAll images have been processed. Results saved to:", output_folder)
